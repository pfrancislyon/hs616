---
title: "Multiple Choice Questions"
author: "Tom De Natale"
date: "March 12, 2015"
output: html_document
---

## Lecture 1a

What are your impressions of day one for HS616 Statistical Computing for Biomedical Data?

* All of these answers
* I should have done the exercises and reading before class 1
* This looks like fun, so I need to get into it
* I should have bought the book earlier
* R we having fun yet?

## Lecture 1b

This is the correct way to set up a chunk of code to run in a RMarkdown file using RStudio?
```r
N<- 10000
```

* True
* False

## Lecture 2a

If you had 2 decks of cards, using the choose function in R, what code will attain the probability of selecting the same specific card from each deck?

* '1/(choose (52,1)* choose(52,1))'
* '1/(choose (52,2))'
* '1/(choose (52,1)* choose(51,2))'
* '1/(choose (2,52))'

## Lecture 2b

Consider a sequence of 10 coin flips, represented by the string `TTTHTHTTTH`. Which statement gives the total number of different sequences of 10 coin flips that could result in this number of heads?

* `paste my own
* `factorial(10)/(factorial(4)*factorial(7))`
* `integrate(dnorm, -Inf, 0)`
* `sapply(3:10, function(x) factorial(x))`

## Lecture 2b 

Concepts that you need to master R in this class do NOT include:

* Fourier Transforms
*	All of these
*	Uniform Distribution(continuous)
*	Normal of Gaussian distribution (continuous)
*	Poisson distribution (discrete)
*	Binomial distribution (discrete)


## Lecture 3a

Which command will create a multiplication table for the numbers from 1 to 10?
Assume `r` is a row vector defined like this: `r <- matrix(1:10,1)`

* pastemyown
* r %*% t(r)
* r^2
* t(r)^2

## Lecture 3b

Given a 2 by 2 matrix `A <- matrix(c(2, 5, 3, 8), 2, byrow=TRUE)`, which command performs Gaussian elimination to put A in upper triangular form?

* pastemy own2,] - A[1,] * 3/2
* A[3,] <- A[3,] - A[2,]
* A[2,] <- A[1,] * 3/8
* A[2,] <- A[2,] + A[1,] + A[1,]/2


## Lecture 4a

Paste my ownto add normally distributed noise to an input vector:
```
addRandom <- function(i) i + rnorm(1)
y <- sapply(0:10, addRandom)
```
How would you change `addRandom` to a vectorized version that could be used like this:
`y <- addRandom(0:10)`? (Choose the best solution)

* `addRandomVectorized <- function(v) v + rnorm(length(v))`
* `addRandomVectorized <- function(i) vapply(i, function(x) x+rnorm(1), 1)`
* `addRandomVectorized <- function(x) sapply(x, addRandom)`
* `addRandomVectorized <- Vectorize(addRandom)`

## Lecture 4b

Pastemyownhe following profiling results:
```
             self.time self.pct
"function_A"    278.39    86.46
"function_B"     29.32     9.10
"function_C"     14.29     4.44
```
If you make `function_B` 100 times faster, how much faster would you expect the program be?

* less than 10% faster
* twice as fast
* 100 times as fast
* no faster

## Lecture 5a

paste my own regular expressions below matches this sentence exactly once?
"The key, the whole key, and nothing but the key."

* "\\.$"
* "[Tt]he\\s"
* "(and|not)"
* "?key?"

## Lecture 5b

paste my ownse addresses cannot be read by the built-in `url()` function?

* `https://connect.usfca.edu`
* `http://rseek.org/`
* `http://ftp.ics.uci.edu/pub/machine-learning-databases/`
* `file:///usr/share/dict/words`

## Lecture 6a

paste my owneturned by the following query?
```
A <- data.frame(a=1:10)
B <- data.frame(b=5:15)
sqldf::sqldf("SELECT * FROM A JOIN B ON a==b")
```

* 6
* 10
* 8
* none

## Lecture 6b

paste my ownnnection to an SQLite database?

* dsets <- dbConnect(RSQLite::SQLite(), "datasets.sqlite")
* res <- dbSendQuery(dsets, "select * from iris limit 10")
* sqliteCopyDatabase(dsets, "datasets.sqlite")
* dbListTables(dsets)

## Lecture 7a

Which is true of Tidy Data by Hadley Wickam?

* None of these other answers
* Data is always essentially tidy
* It is always possible to get to the ideal structure, that is attain a one to one relationship for all data
* It is bad for vectorization to have each observation in a row
* It is good to have the variables identified at the start of a row versus the variable as a column
* Wide tables with a unique entry for the first element each row are always better  than long tables which may have nonunique entries as the first element in multiple rows.

